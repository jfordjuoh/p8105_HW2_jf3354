p8105\_hw2\_jf3354
================
Judy Fordjuoh
October 2, 2021

\#\#\#PROBLEM ONE \#\#Creating the dataframe

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──

    ## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
    ## ✓ tibble  3.1.4     ✓ dplyr   1.0.7
    ## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
    ## ✓ readr   2.0.1     ✓ forcats 0.5.1

    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(haven)
library(dplyr)
```

\#\#This was the pathname i wanted to use import the Mr.Trash file and
it didnt work. Kept saying Error: ‘path’ does not exist. Why? 1. TW\_df
= read\_excel(“./Data Science/p8105\_HW2\_jf3354/MrTrash.xlsx”, sheet =
‘MrTrashWheel’) 2. TW\_df =
read\_excel(“./p8105\_HW2\_jf3354/MrTrash.xlsx”, sheet = ‘MrTrashWheel’)

\#what exactly is dumpster-specific data? I removed all the total rows

\#Line 23 there is a problem with my mutate statement. Works when i run
it individually but is preventing my document from knitting.

\#\#Problem 1

``` r
TW_df = read_excel("MrTrash.xlsx", sheet = 'MrTrashWheel', range = 'A2:N408') %>%
    janitor::clean_names() %>%
    mutate(sports_balls = round(sports_balls)) %>%
    drop_na(dumpster) #dropping all the rows in dumpster that has a NA
    
summary(TW_df)
```

    ##     dumpster         month                year     
    ##  Min.   :  1.00   Length:344         Min.   :2014  
    ##  1st Qu.: 86.75   Class :character   1st Qu.:2015  
    ##  Median :172.50   Mode  :character   Median :2017  
    ##  Mean   :172.50                      Mean   :2016  
    ##  3rd Qu.:258.25                      3rd Qu.:2018  
    ##  Max.   :344.00                      Max.   :2019  
    ##       date                      weight_tons    volume_cubic_yards
    ##  Min.   :2014-05-16 00:00:00   Min.   :0.960   Min.   : 7.00     
    ##  1st Qu.:2015-07-05 00:00:00   1st Qu.:2.757   1st Qu.:15.00     
    ##  Median :2017-03-31 00:00:00   Median :3.265   Median :15.00     
    ##  Mean   :2016-12-23 10:57:12   Mean   :3.263   Mean   :15.54     
    ##  3rd Qu.:2018-05-19 18:00:00   3rd Qu.:3.772   3rd Qu.:16.00     
    ##  Max.   :2019-06-17 00:00:00   Max.   :5.620   Max.   :20.00     
    ##  plastic_bottles   polystyrene   cigarette_butts  glass_bottles   
    ##  Min.   : 210.0   Min.   : 320   Min.   :   980   Min.   :  0.00  
    ##  1st Qu.: 957.5   1st Qu.:1065   1st Qu.:  7000   1st Qu.: 10.00  
    ##  Median :1835.0   Median :2075   Median : 19000   Median : 21.50  
    ##  Mean   :1873.2   Mean   :2139   Mean   : 30754   Mean   : 25.36  
    ##  3rd Qu.:2552.5   3rd Qu.:3120   3rd Qu.: 38000   3rd Qu.: 38.00  
    ##  Max.   :5960.0   Max.   :6540   Max.   :310000   Max.   :110.00  
    ##   grocery_bags    chip_bags       sports_balls   homes_powered  
    ##  Min.   :  50   Min.   : 230.0   Min.   : 0.00   Min.   : 0.00  
    ##  1st Qu.: 600   1st Qu.: 977.5   1st Qu.: 5.00   1st Qu.:35.62  
    ##  Median :1050   Median :1630.0   Median : 8.00   Median :51.42  
    ##  Mean   :1311   Mean   :1780.3   Mean   :11.81   Mean   :43.83  
    ##  3rd Qu.:1912   3rd Qu.:2490.0   3rd Qu.:16.00   3rd Qu.:59.50  
    ##  Max.   :3750   Max.   :5085.0   Max.   :56.00   Max.   :93.67

``` r
skimr::skim(TW_df)
```

|                                                  |        |
|:-------------------------------------------------|:-------|
| Name                                             | TW\_df |
| Number of rows                                   | 344    |
| Number of columns                                | 14     |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |        |
| Column type frequency:                           |        |
| character                                        | 1      |
| numeric                                          | 12     |
| POSIXct                                          | 1      |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |        |
| Group variables                                  | None   |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
|:---------------|-----------:|---------------:|----:|----:|------:|----------:|-----------:|
| month          |          0 |              1 |   3 |   9 |     0 |        12 |          0 |

**Variable type: numeric**

| skim\_variable       | n\_missing | complete\_rate |     mean |       sd |      p0 |     p25 |      p50 |      p75 |      p100 | hist  |
|:---------------------|-----------:|---------------:|---------:|---------:|--------:|--------:|---------:|---------:|----------:|:------|
| dumpster             |          0 |              1 |   172.50 |    99.45 |    1.00 |   86.75 |   172.50 |   258.25 |    344.00 | ▇▇▇▇▇ |
| year                 |          0 |              1 |  2016.50 |     1.58 | 2014.00 | 2015.00 |  2017.00 |  2018.00 |   2019.00 | ▇▃▃▆▂ |
| weight\_tons         |          0 |              1 |     3.26 |     0.75 |    0.96 |    2.76 |     3.26 |     3.77 |      5.62 | ▁▅▇▅▁ |
| volume\_cubic\_yards |          0 |              1 |    15.54 |     1.68 |    7.00 |   15.00 |    15.00 |    16.00 |     20.00 | ▁▁▁▇▂ |
| plastic\_bottles     |          0 |              1 |  1873.15 |  1028.87 |  210.00 |  957.50 |  1835.00 |  2552.50 |   5960.00 | ▇▆▅▁▁ |
| polystyrene          |          0 |              1 |  2138.68 |  1202.82 |  320.00 | 1065.00 |  2075.00 |  3120.00 |   6540.00 | ▇▆▅▁▁ |
| cigarette\_butts     |          0 |              1 | 30754.13 | 34492.50 |  980.00 | 7000.00 | 19000.00 | 38000.00 | 310000.00 | ▇▁▁▁▁ |
| glass\_bottles       |          0 |              1 |    25.36 |    18.64 |    0.00 |   10.00 |    21.50 |    38.00 |    110.00 | ▇▅▂▁▁ |
| grocery\_bags        |          0 |              1 |  1311.23 |   881.87 |   50.00 |  600.00 |  1050.00 |  1912.50 |   3750.00 | ▇▇▅▃▁ |
| chip\_bags           |          0 |              1 |  1780.27 |   956.53 |  230.00 |  977.50 |  1630.00 |  2490.00 |   5085.00 | ▇▇▅▂▁ |
| sports\_balls        |          0 |              1 |    11.81 |     9.81 |    0.00 |    5.00 |     8.00 |    16.00 |     56.00 | ▇▃▁▁▁ |
| homes\_powered       |          0 |              1 |    43.83 |    23.98 |    0.00 |   35.62 |    51.42 |    59.50 |     93.67 | ▅▂▇▆▁ |

**Variable type: POSIXct**

| skim\_variable | n\_missing | complete\_rate | min        | max        | median     | n\_unique |
|:---------------|-----------:|---------------:|:-----------|:-----------|:-----------|----------:|
| date           |          0 |              1 | 2014-05-16 | 2019-06-17 | 2017-03-31 |       217 |

``` r
str(TW_df)
```

    ## tibble [344 × 14] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:344] "May" "May" "May" "May" ...
    ##  $ year              : num [1:344] 2014 2014 2014 2014 2014 ...
    ##  $ date              : POSIXct[1:344], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:344] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:344] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:344] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:344] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:344] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:344] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ grocery_bags      : num [1:344] 584 496 1080 896 368 ...
    ##  $ chip_bags         : num [1:344] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : num [1:344] 7 5 6 6 7 5 3 6 6 7 ...
    ##  $ homes_powered     : num [1:344] 0 0 0 0 0 0 0 0 0 0 ...

``` r
prep_2019 = read_excel("MrTrash.xlsx", sheet = '2019 Precipitation',range = 'A2:B14') %>%
  drop_na() %>%
  mutate(year = "2019")
   
prep_2018 = read_excel("MrTrash.xlsx", sheet = '2018 Precipitation', range = 'A2:B14') %>%  
    mutate(year = "2018")
    
##I also got rid of the last row which was the total precipitations

precip18_19 = 
  bind_rows(prep_2019, prep_2018) %>%
  mutate(Month = month.name[Month]) %>%
  arrange(Month, Total, year)
```

precip18\_19,

### Question: Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2018? What was the median number of sports balls in a dumpster in 2019? ANSWER THIS

\#p\_m = read\_csv(“./fivethirtyeight\_dataset/pols\_month.csv”). \#Do
we have to change the year fomrat from two digits to 4 in s\_np? YES
\#mutate(Date = as.Date(date, format = “%M/%D/%Y”)) \#President:
1=Democrat 0=Repubs

\#\#Problem 2

``` r
p_m = read_csv("pols-month.csv") %>%
  separate(mon, c("Year", "Month", "Day")) %>%
  mutate(Month = month.name[as.numeric(Month)]) %>%
  mutate(president = ifelse(is.na(prez_dem), prez_gop, prez_dem )) %>%
  select(-prez_dem, -prez_gop, -Day)
```

    ## Rows: 822 Columns: 9

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
s_np = read_csv("snp.csv") %>%
  separate(date, c("Day", "Month", "year")) %>%
  mutate(year = as.numeric(year)) %>%
  mutate(year = if_else(year >= 50,
                        year + 1900,
                        year + 2000)) %>%
  arrange(year,Month) %>% 
  mutate(Month = (month.name[as.numeric(Month)])) %>%
  select(year, Month, everything()) 
```

    ## Rows: 787 Columns: 2

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
un_emp = read_csv("unemployment.csv") 
```

    ## Rows: 68 Columns: 13

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
un_emp_tidy =
  un_emp %>%
  pivot_longer(
    Jan:Dec, 
    names_to = 'Month',
    values_to = 'Percentage'
  )

## Join the datasets by merging snp into pols, and merging unemployment into the result. So we will join them by year while doing a left-join. We will do an inner join. 
```

\#\#Write a short paragraph about these datasets. Explain briefly what
each dataset contained, and describe the resulting dataset (e.g. give
the dimension, range of years, and names of key variables).

\#\#Problem 3

``` r
Pbn = read_csv("Popular_Baby_Names.csv")
```

    ## Rows: 19418 Columns: 6

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Gender, Ethnicity, Child's First Name
    ## dbl (3): Year of Birth, Count, Rank

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
